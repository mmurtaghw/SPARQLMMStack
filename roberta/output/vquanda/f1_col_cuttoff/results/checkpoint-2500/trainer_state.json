{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 50.0,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 5.416381359100342,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.6166,
      "step": 10
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.7066588401794434,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.5999,
      "step": 20
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.096225738525391,
      "learning_rate": 3e-06,
      "loss": 0.5875,
      "step": 30
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.846798896789551,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.5475,
      "step": 40
    },
    {
      "epoch": 1.0,
      "grad_norm": 16.62728500366211,
      "learning_rate": 5e-06,
      "loss": 0.5029,
      "step": 50
    },
    {
      "epoch": 1.2,
      "grad_norm": 6.116003036499023,
      "learning_rate": 6e-06,
      "loss": 0.4683,
      "step": 60
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.070309638977051,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.4855,
      "step": 70
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.9655256271362305,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.4737,
      "step": 80
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.644178867340088,
      "learning_rate": 9e-06,
      "loss": 0.4675,
      "step": 90
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.5684733390808105,
      "learning_rate": 1e-05,
      "loss": 0.4287,
      "step": 100
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.4123876094818115,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.4666,
      "step": 110
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.659984588623047,
      "learning_rate": 1.2e-05,
      "loss": 0.4677,
      "step": 120
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.881941795349121,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.448,
      "step": 130
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.3763411045074463,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.4592,
      "step": 140
    },
    {
      "epoch": 3.0,
      "grad_norm": 15.786661148071289,
      "learning_rate": 1.5e-05,
      "loss": 0.4561,
      "step": 150
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.4168248176574707,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.4304,
      "step": 160
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.4485628604888916,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.466,
      "step": 170
    },
    {
      "epoch": 3.6,
      "grad_norm": 2.894129514694214,
      "learning_rate": 1.8e-05,
      "loss": 0.4459,
      "step": 180
    },
    {
      "epoch": 3.8,
      "grad_norm": 6.811255931854248,
      "learning_rate": 1.9e-05,
      "loss": 0.4553,
      "step": 190
    },
    {
      "epoch": 4.0,
      "grad_norm": 27.61453628540039,
      "learning_rate": 2e-05,
      "loss": 0.4257,
      "step": 200
    },
    {
      "epoch": 4.2,
      "grad_norm": 3.2305757999420166,
      "learning_rate": 2.1e-05,
      "loss": 0.431,
      "step": 210
    },
    {
      "epoch": 4.4,
      "grad_norm": 3.348280191421509,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.4446,
      "step": 220
    },
    {
      "epoch": 4.6,
      "grad_norm": 3.16499662399292,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.4352,
      "step": 230
    },
    {
      "epoch": 4.8,
      "grad_norm": 4.692127227783203,
      "learning_rate": 2.4e-05,
      "loss": 0.4456,
      "step": 240
    },
    {
      "epoch": 5.0,
      "grad_norm": 7.091489791870117,
      "learning_rate": 2.5e-05,
      "loss": 0.4535,
      "step": 250
    },
    {
      "epoch": 5.2,
      "grad_norm": 4.719548225402832,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.4256,
      "step": 260
    },
    {
      "epoch": 5.4,
      "grad_norm": 4.332059860229492,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.4315,
      "step": 270
    },
    {
      "epoch": 5.6,
      "grad_norm": 7.759339332580566,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.4194,
      "step": 280
    },
    {
      "epoch": 5.8,
      "grad_norm": 144.98995971679688,
      "learning_rate": 2.9e-05,
      "loss": 0.4251,
      "step": 290
    },
    {
      "epoch": 6.0,
      "grad_norm": 13.877859115600586,
      "learning_rate": 3e-05,
      "loss": 0.4336,
      "step": 300
    },
    {
      "epoch": 6.2,
      "grad_norm": 8.631360054016113,
      "learning_rate": 3.1e-05,
      "loss": 0.3991,
      "step": 310
    },
    {
      "epoch": 6.4,
      "grad_norm": 4.411318778991699,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.3771,
      "step": 320
    },
    {
      "epoch": 6.6,
      "grad_norm": 5.617405414581299,
      "learning_rate": 3.3e-05,
      "loss": 0.3872,
      "step": 330
    },
    {
      "epoch": 6.8,
      "grad_norm": 3.999978542327881,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.411,
      "step": 340
    },
    {
      "epoch": 7.0,
      "grad_norm": 19.89973258972168,
      "learning_rate": 3.5e-05,
      "loss": 0.4044,
      "step": 350
    },
    {
      "epoch": 7.2,
      "grad_norm": 4.512328147888184,
      "learning_rate": 3.6e-05,
      "loss": 0.3147,
      "step": 360
    },
    {
      "epoch": 7.4,
      "grad_norm": 12.263126373291016,
      "learning_rate": 3.7e-05,
      "loss": 0.3411,
      "step": 370
    },
    {
      "epoch": 7.6,
      "grad_norm": 14.587217330932617,
      "learning_rate": 3.8e-05,
      "loss": 0.3763,
      "step": 380
    },
    {
      "epoch": 7.8,
      "grad_norm": 6.8649444580078125,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.4127,
      "step": 390
    },
    {
      "epoch": 8.0,
      "grad_norm": 8.865250587463379,
      "learning_rate": 4e-05,
      "loss": 0.352,
      "step": 400
    },
    {
      "epoch": 8.2,
      "grad_norm": 9.283970832824707,
      "learning_rate": 4.1e-05,
      "loss": 0.3549,
      "step": 410
    },
    {
      "epoch": 8.4,
      "grad_norm": 9.946747779846191,
      "learning_rate": 4.2e-05,
      "loss": 0.3256,
      "step": 420
    },
    {
      "epoch": 8.6,
      "grad_norm": 5.9894700050354,
      "learning_rate": 4.3e-05,
      "loss": 0.3037,
      "step": 430
    },
    {
      "epoch": 8.8,
      "grad_norm": 6.20660400390625,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.3212,
      "step": 440
    },
    {
      "epoch": 9.0,
      "grad_norm": 35.529876708984375,
      "learning_rate": 4.5e-05,
      "loss": 0.2846,
      "step": 450
    },
    {
      "epoch": 9.2,
      "grad_norm": 3.564937114715576,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.2536,
      "step": 460
    },
    {
      "epoch": 9.4,
      "grad_norm": 10.278141975402832,
      "learning_rate": 4.7e-05,
      "loss": 0.2778,
      "step": 470
    },
    {
      "epoch": 9.6,
      "grad_norm": 9.245558738708496,
      "learning_rate": 4.8e-05,
      "loss": 0.2585,
      "step": 480
    },
    {
      "epoch": 9.8,
      "grad_norm": 21.49949073791504,
      "learning_rate": 4.9e-05,
      "loss": 0.2676,
      "step": 490
    },
    {
      "epoch": 10.0,
      "grad_norm": 37.87412643432617,
      "learning_rate": 5e-05,
      "loss": 0.4216,
      "step": 500
    },
    {
      "epoch": 10.2,
      "grad_norm": 10.25745677947998,
      "learning_rate": 4.975e-05,
      "loss": 0.3,
      "step": 510
    },
    {
      "epoch": 10.4,
      "grad_norm": 6.390731334686279,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.2058,
      "step": 520
    },
    {
      "epoch": 10.6,
      "grad_norm": 14.059226989746094,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 0.162,
      "step": 530
    },
    {
      "epoch": 10.8,
      "grad_norm": 10.30742073059082,
      "learning_rate": 4.9e-05,
      "loss": 0.2028,
      "step": 540
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.1422215700149536,
      "learning_rate": 4.875e-05,
      "loss": 0.2189,
      "step": 550
    },
    {
      "epoch": 11.2,
      "grad_norm": 7.448971271514893,
      "learning_rate": 4.85e-05,
      "loss": 0.1617,
      "step": 560
    },
    {
      "epoch": 11.4,
      "grad_norm": 6.362188816070557,
      "learning_rate": 4.825e-05,
      "loss": 0.1972,
      "step": 570
    },
    {
      "epoch": 11.6,
      "grad_norm": 14.887420654296875,
      "learning_rate": 4.8e-05,
      "loss": 0.1979,
      "step": 580
    },
    {
      "epoch": 11.8,
      "grad_norm": 8.188197135925293,
      "learning_rate": 4.775e-05,
      "loss": 0.1784,
      "step": 590
    },
    {
      "epoch": 12.0,
      "grad_norm": 20.136476516723633,
      "learning_rate": 4.75e-05,
      "loss": 0.1883,
      "step": 600
    },
    {
      "epoch": 12.2,
      "grad_norm": 4.364152908325195,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 0.1155,
      "step": 610
    },
    {
      "epoch": 12.4,
      "grad_norm": 7.663088321685791,
      "learning_rate": 4.7e-05,
      "loss": 0.1032,
      "step": 620
    },
    {
      "epoch": 12.6,
      "grad_norm": 5.4828925132751465,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 0.1166,
      "step": 630
    },
    {
      "epoch": 12.8,
      "grad_norm": 17.447582244873047,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.1015,
      "step": 640
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.2782238721847534,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 0.1124,
      "step": 650
    },
    {
      "epoch": 13.2,
      "grad_norm": 0.8905820846557617,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.1112,
      "step": 660
    },
    {
      "epoch": 13.4,
      "grad_norm": 15.915475845336914,
      "learning_rate": 4.575e-05,
      "loss": 0.0813,
      "step": 670
    },
    {
      "epoch": 13.6,
      "grad_norm": 14.71435832977295,
      "learning_rate": 4.55e-05,
      "loss": 0.1101,
      "step": 680
    },
    {
      "epoch": 13.8,
      "grad_norm": 14.91777515411377,
      "learning_rate": 4.525e-05,
      "loss": 0.1302,
      "step": 690
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.2118435651063919,
      "learning_rate": 4.5e-05,
      "loss": 0.1675,
      "step": 700
    },
    {
      "epoch": 14.2,
      "grad_norm": 15.07413101196289,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 0.0787,
      "step": 710
    },
    {
      "epoch": 14.4,
      "grad_norm": 4.886984348297119,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.103,
      "step": 720
    },
    {
      "epoch": 14.6,
      "grad_norm": 5.335576057434082,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 0.1126,
      "step": 730
    },
    {
      "epoch": 14.8,
      "grad_norm": 6.43271541595459,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0833,
      "step": 740
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.8162596225738525,
      "learning_rate": 4.375e-05,
      "loss": 0.0996,
      "step": 750
    },
    {
      "epoch": 15.2,
      "grad_norm": 2.8722786903381348,
      "learning_rate": 4.35e-05,
      "loss": 0.0678,
      "step": 760
    },
    {
      "epoch": 15.4,
      "grad_norm": 12.14682674407959,
      "learning_rate": 4.325e-05,
      "loss": 0.0658,
      "step": 770
    },
    {
      "epoch": 15.6,
      "grad_norm": 12.883795738220215,
      "learning_rate": 4.3e-05,
      "loss": 0.0758,
      "step": 780
    },
    {
      "epoch": 15.8,
      "grad_norm": 2.2407944202423096,
      "learning_rate": 4.275e-05,
      "loss": 0.0571,
      "step": 790
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.5151984095573425,
      "learning_rate": 4.25e-05,
      "loss": 0.055,
      "step": 800
    },
    {
      "epoch": 16.2,
      "grad_norm": 1.1301548480987549,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 0.0452,
      "step": 810
    },
    {
      "epoch": 16.4,
      "grad_norm": 0.38737809658050537,
      "learning_rate": 4.2e-05,
      "loss": 0.0321,
      "step": 820
    },
    {
      "epoch": 16.6,
      "grad_norm": 14.963407516479492,
      "learning_rate": 4.175e-05,
      "loss": 0.046,
      "step": 830
    },
    {
      "epoch": 16.8,
      "grad_norm": 9.937723159790039,
      "learning_rate": 4.15e-05,
      "loss": 0.0654,
      "step": 840
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.8920624256134033,
      "learning_rate": 4.125e-05,
      "loss": 0.0424,
      "step": 850
    },
    {
      "epoch": 17.2,
      "grad_norm": 0.5222206115722656,
      "learning_rate": 4.1e-05,
      "loss": 0.0371,
      "step": 860
    },
    {
      "epoch": 17.4,
      "grad_norm": 4.9141693115234375,
      "learning_rate": 4.075e-05,
      "loss": 0.0726,
      "step": 870
    },
    {
      "epoch": 17.6,
      "grad_norm": 11.804271697998047,
      "learning_rate": 4.05e-05,
      "loss": 0.0421,
      "step": 880
    },
    {
      "epoch": 17.8,
      "grad_norm": 26.418672561645508,
      "learning_rate": 4.025e-05,
      "loss": 0.0347,
      "step": 890
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.11943147331476212,
      "learning_rate": 4e-05,
      "loss": 0.058,
      "step": 900
    },
    {
      "epoch": 18.2,
      "grad_norm": 22.91827964782715,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 0.0379,
      "step": 910
    },
    {
      "epoch": 18.4,
      "grad_norm": 1.5354869365692139,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.0426,
      "step": 920
    },
    {
      "epoch": 18.6,
      "grad_norm": 13.076990127563477,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 0.041,
      "step": 930
    },
    {
      "epoch": 18.8,
      "grad_norm": 0.15815132856369019,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0096,
      "step": 940
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.04053555428981781,
      "learning_rate": 3.875e-05,
      "loss": 0.0321,
      "step": 950
    },
    {
      "epoch": 19.2,
      "grad_norm": 47.443328857421875,
      "learning_rate": 3.85e-05,
      "loss": 0.0481,
      "step": 960
    },
    {
      "epoch": 19.4,
      "grad_norm": 0.19952483475208282,
      "learning_rate": 3.825e-05,
      "loss": 0.0202,
      "step": 970
    },
    {
      "epoch": 19.6,
      "grad_norm": 5.373530387878418,
      "learning_rate": 3.8e-05,
      "loss": 0.0064,
      "step": 980
    },
    {
      "epoch": 19.8,
      "grad_norm": 12.734884262084961,
      "learning_rate": 3.775e-05,
      "loss": 0.0135,
      "step": 990
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.06180759146809578,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.057,
      "step": 1000
    },
    {
      "epoch": 20.2,
      "grad_norm": 0.028080111369490623,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.0037,
      "step": 1010
    },
    {
      "epoch": 20.4,
      "grad_norm": 23.894845962524414,
      "learning_rate": 3.7e-05,
      "loss": 0.024,
      "step": 1020
    },
    {
      "epoch": 20.6,
      "grad_norm": 7.361728191375732,
      "learning_rate": 3.675e-05,
      "loss": 0.0358,
      "step": 1030
    },
    {
      "epoch": 20.8,
      "grad_norm": 22.99827766418457,
      "learning_rate": 3.65e-05,
      "loss": 0.036,
      "step": 1040
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.16908833384513855,
      "learning_rate": 3.625e-05,
      "loss": 0.0155,
      "step": 1050
    },
    {
      "epoch": 21.2,
      "grad_norm": 10.51240062713623,
      "learning_rate": 3.6e-05,
      "loss": 0.0325,
      "step": 1060
    },
    {
      "epoch": 21.4,
      "grad_norm": 0.035590700805187225,
      "learning_rate": 3.575e-05,
      "loss": 0.003,
      "step": 1070
    },
    {
      "epoch": 21.6,
      "grad_norm": 0.2954527735710144,
      "learning_rate": 3.55e-05,
      "loss": 0.0082,
      "step": 1080
    },
    {
      "epoch": 21.8,
      "grad_norm": 4.809135437011719,
      "learning_rate": 3.525e-05,
      "loss": 0.0224,
      "step": 1090
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.03013990819454193,
      "learning_rate": 3.5e-05,
      "loss": 0.0337,
      "step": 1100
    },
    {
      "epoch": 22.2,
      "grad_norm": 0.12189798802137375,
      "learning_rate": 3.475e-05,
      "loss": 0.0025,
      "step": 1110
    },
    {
      "epoch": 22.4,
      "grad_norm": 0.06779990345239639,
      "learning_rate": 3.45e-05,
      "loss": 0.0201,
      "step": 1120
    },
    {
      "epoch": 22.6,
      "grad_norm": 25.757953643798828,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 0.0081,
      "step": 1130
    },
    {
      "epoch": 22.8,
      "grad_norm": 0.02084682509303093,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0129,
      "step": 1140
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.019288575276732445,
      "learning_rate": 3.375000000000001e-05,
      "loss": 0.0114,
      "step": 1150
    },
    {
      "epoch": 23.2,
      "grad_norm": 0.2699843943119049,
      "learning_rate": 3.35e-05,
      "loss": 0.0028,
      "step": 1160
    },
    {
      "epoch": 23.4,
      "grad_norm": 0.09051124006509781,
      "learning_rate": 3.325e-05,
      "loss": 0.0019,
      "step": 1170
    },
    {
      "epoch": 23.6,
      "grad_norm": 0.016167543828487396,
      "learning_rate": 3.3e-05,
      "loss": 0.0027,
      "step": 1180
    },
    {
      "epoch": 23.8,
      "grad_norm": 0.024914149194955826,
      "learning_rate": 3.275e-05,
      "loss": 0.0327,
      "step": 1190
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.06926195323467255,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.0049,
      "step": 1200
    },
    {
      "epoch": 24.2,
      "grad_norm": 2.2729101181030273,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 0.0023,
      "step": 1210
    },
    {
      "epoch": 24.4,
      "grad_norm": 4.252981185913086,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0029,
      "step": 1220
    },
    {
      "epoch": 24.6,
      "grad_norm": 0.019703160971403122,
      "learning_rate": 3.175e-05,
      "loss": 0.0019,
      "step": 1230
    },
    {
      "epoch": 24.8,
      "grad_norm": 50.65092086791992,
      "learning_rate": 3.15e-05,
      "loss": 0.0175,
      "step": 1240
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.2698727548122406,
      "learning_rate": 3.125e-05,
      "loss": 0.019,
      "step": 1250
    },
    {
      "epoch": 25.2,
      "grad_norm": 0.010260171256959438,
      "learning_rate": 3.1e-05,
      "loss": 0.0016,
      "step": 1260
    },
    {
      "epoch": 25.4,
      "grad_norm": 0.8773599863052368,
      "learning_rate": 3.075e-05,
      "loss": 0.0129,
      "step": 1270
    },
    {
      "epoch": 25.6,
      "grad_norm": 0.010926862247288227,
      "learning_rate": 3.05e-05,
      "loss": 0.0187,
      "step": 1280
    },
    {
      "epoch": 25.8,
      "grad_norm": 0.06373871117830276,
      "learning_rate": 3.025e-05,
      "loss": 0.0019,
      "step": 1290
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.024468451738357544,
      "learning_rate": 3e-05,
      "loss": 0.0019,
      "step": 1300
    },
    {
      "epoch": 26.2,
      "grad_norm": 0.02221583016216755,
      "learning_rate": 2.975e-05,
      "loss": 0.0031,
      "step": 1310
    },
    {
      "epoch": 26.4,
      "grad_norm": 0.01929025538265705,
      "learning_rate": 2.95e-05,
      "loss": 0.0017,
      "step": 1320
    },
    {
      "epoch": 26.6,
      "grad_norm": 0.011257536709308624,
      "learning_rate": 2.925e-05,
      "loss": 0.0022,
      "step": 1330
    },
    {
      "epoch": 26.8,
      "grad_norm": 0.013380616903305054,
      "learning_rate": 2.9e-05,
      "loss": 0.0024,
      "step": 1340
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.37051159143447876,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 0.0019,
      "step": 1350
    },
    {
      "epoch": 27.2,
      "grad_norm": 0.010499428026378155,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.0014,
      "step": 1360
    },
    {
      "epoch": 27.4,
      "grad_norm": 0.008228504098951817,
      "learning_rate": 2.825e-05,
      "loss": 0.0015,
      "step": 1370
    },
    {
      "epoch": 27.6,
      "grad_norm": 0.010240660980343819,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0015,
      "step": 1380
    },
    {
      "epoch": 27.8,
      "grad_norm": 0.01817188411951065,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 0.0014,
      "step": 1390
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.01645917072892189,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.0057,
      "step": 1400
    },
    {
      "epoch": 28.2,
      "grad_norm": 0.00772279454395175,
      "learning_rate": 2.725e-05,
      "loss": 0.0013,
      "step": 1410
    },
    {
      "epoch": 28.4,
      "grad_norm": 0.01736236736178398,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0013,
      "step": 1420
    },
    {
      "epoch": 28.6,
      "grad_norm": 0.007244516164064407,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 0.0013,
      "step": 1430
    },
    {
      "epoch": 28.8,
      "grad_norm": 0.00855657085776329,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 0.0012,
      "step": 1440
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.013346455991268158,
      "learning_rate": 2.625e-05,
      "loss": 0.0012,
      "step": 1450
    },
    {
      "epoch": 29.2,
      "grad_norm": 0.014482628554105759,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0012,
      "step": 1460
    },
    {
      "epoch": 29.4,
      "grad_norm": 0.008542167954146862,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 0.0012,
      "step": 1470
    },
    {
      "epoch": 29.6,
      "grad_norm": 0.008734805509448051,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 0.0012,
      "step": 1480
    },
    {
      "epoch": 29.8,
      "grad_norm": 0.013752174563705921,
      "learning_rate": 2.525e-05,
      "loss": 0.0012,
      "step": 1490
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.0281352698802948,
      "learning_rate": 2.5e-05,
      "loss": 0.0012,
      "step": 1500
    },
    {
      "epoch": 30.2,
      "grad_norm": 0.006954986602067947,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 0.0012,
      "step": 1510
    },
    {
      "epoch": 30.4,
      "grad_norm": 0.008058668114244938,
      "learning_rate": 2.45e-05,
      "loss": 0.0011,
      "step": 1520
    },
    {
      "epoch": 30.6,
      "grad_norm": 0.007136053871363401,
      "learning_rate": 2.425e-05,
      "loss": 0.015,
      "step": 1530
    },
    {
      "epoch": 30.8,
      "grad_norm": 0.12924833595752716,
      "learning_rate": 2.4e-05,
      "loss": 0.0011,
      "step": 1540
    },
    {
      "epoch": 31.0,
      "grad_norm": 0.011922440491616726,
      "learning_rate": 2.375e-05,
      "loss": 0.0011,
      "step": 1550
    },
    {
      "epoch": 31.2,
      "grad_norm": 0.007251226343214512,
      "learning_rate": 2.35e-05,
      "loss": 0.001,
      "step": 1560
    },
    {
      "epoch": 31.4,
      "grad_norm": 0.00964727345854044,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 0.0011,
      "step": 1570
    },
    {
      "epoch": 31.6,
      "grad_norm": 3.2751729488372803,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.0012,
      "step": 1580
    },
    {
      "epoch": 31.8,
      "grad_norm": 0.006444512400776148,
      "learning_rate": 2.275e-05,
      "loss": 0.001,
      "step": 1590
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.6411417722702026,
      "learning_rate": 2.25e-05,
      "loss": 0.0012,
      "step": 1600
    },
    {
      "epoch": 32.2,
      "grad_norm": 0.0058262040838599205,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 0.0109,
      "step": 1610
    },
    {
      "epoch": 32.4,
      "grad_norm": 0.009232085198163986,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.001,
      "step": 1620
    },
    {
      "epoch": 32.6,
      "grad_norm": 0.006202251184731722,
      "learning_rate": 2.175e-05,
      "loss": 0.001,
      "step": 1630
    },
    {
      "epoch": 32.8,
      "grad_norm": 0.005970638245344162,
      "learning_rate": 2.15e-05,
      "loss": 0.001,
      "step": 1640
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.017670363187789917,
      "learning_rate": 2.125e-05,
      "loss": 0.001,
      "step": 1650
    },
    {
      "epoch": 33.2,
      "grad_norm": 0.005837063305079937,
      "learning_rate": 2.1e-05,
      "loss": 0.001,
      "step": 1660
    },
    {
      "epoch": 33.4,
      "grad_norm": 0.00901726819574833,
      "learning_rate": 2.075e-05,
      "loss": 0.001,
      "step": 1670
    },
    {
      "epoch": 33.6,
      "grad_norm": 0.005754925310611725,
      "learning_rate": 2.05e-05,
      "loss": 0.0009,
      "step": 1680
    },
    {
      "epoch": 33.8,
      "grad_norm": 0.006054514553397894,
      "learning_rate": 2.025e-05,
      "loss": 0.001,
      "step": 1690
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.024282492697238922,
      "learning_rate": 2e-05,
      "loss": 0.001,
      "step": 1700
    },
    {
      "epoch": 34.2,
      "grad_norm": 0.005683984141796827,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 0.0009,
      "step": 1710
    },
    {
      "epoch": 34.4,
      "grad_norm": 0.005474879872053862,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 0.0015,
      "step": 1720
    },
    {
      "epoch": 34.6,
      "grad_norm": 0.01028137281537056,
      "learning_rate": 1.925e-05,
      "loss": 0.0009,
      "step": 1730
    },
    {
      "epoch": 34.8,
      "grad_norm": 0.006481661926954985,
      "learning_rate": 1.9e-05,
      "loss": 0.0009,
      "step": 1740
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.00956864096224308,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.0009,
      "step": 1750
    },
    {
      "epoch": 35.2,
      "grad_norm": 0.006048060487955809,
      "learning_rate": 1.85e-05,
      "loss": 0.0065,
      "step": 1760
    },
    {
      "epoch": 35.4,
      "grad_norm": 0.0060201226733624935,
      "learning_rate": 1.825e-05,
      "loss": 0.0009,
      "step": 1770
    },
    {
      "epoch": 35.6,
      "grad_norm": 0.006232109386473894,
      "learning_rate": 1.8e-05,
      "loss": 0.0009,
      "step": 1780
    },
    {
      "epoch": 35.8,
      "grad_norm": 0.005334880203008652,
      "learning_rate": 1.775e-05,
      "loss": 0.0008,
      "step": 1790
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.006245845928788185,
      "learning_rate": 1.75e-05,
      "loss": 0.0008,
      "step": 1800
    },
    {
      "epoch": 36.2,
      "grad_norm": 0.006010834593325853,
      "learning_rate": 1.725e-05,
      "loss": 0.0046,
      "step": 1810
    },
    {
      "epoch": 36.4,
      "grad_norm": 0.011194123886525631,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.0009,
      "step": 1820
    },
    {
      "epoch": 36.6,
      "grad_norm": 0.011756504885852337,
      "learning_rate": 1.675e-05,
      "loss": 0.0008,
      "step": 1830
    },
    {
      "epoch": 36.8,
      "grad_norm": 0.00527507858350873,
      "learning_rate": 1.65e-05,
      "loss": 0.0008,
      "step": 1840
    },
    {
      "epoch": 37.0,
      "grad_norm": 0.009352296590805054,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.0008,
      "step": 1850
    },
    {
      "epoch": 37.2,
      "grad_norm": 0.006336832884699106,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0008,
      "step": 1860
    },
    {
      "epoch": 37.4,
      "grad_norm": 0.006643553264439106,
      "learning_rate": 1.575e-05,
      "loss": 0.0008,
      "step": 1870
    },
    {
      "epoch": 37.6,
      "grad_norm": 0.007650194689631462,
      "learning_rate": 1.55e-05,
      "loss": 0.0008,
      "step": 1880
    },
    {
      "epoch": 37.8,
      "grad_norm": 0.004880940075963736,
      "learning_rate": 1.525e-05,
      "loss": 0.0008,
      "step": 1890
    },
    {
      "epoch": 38.0,
      "grad_norm": 0.007308617699891329,
      "learning_rate": 1.5e-05,
      "loss": 0.0008,
      "step": 1900
    },
    {
      "epoch": 38.2,
      "grad_norm": 0.009653525426983833,
      "learning_rate": 1.475e-05,
      "loss": 0.0008,
      "step": 1910
    },
    {
      "epoch": 38.4,
      "grad_norm": 0.0057388232089579105,
      "learning_rate": 1.45e-05,
      "loss": 0.0007,
      "step": 1920
    },
    {
      "epoch": 38.6,
      "grad_norm": 0.005230103153735399,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 0.0008,
      "step": 1930
    },
    {
      "epoch": 38.8,
      "grad_norm": 0.0189674012362957,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0008,
      "step": 1940
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.006694858428090811,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 0.0008,
      "step": 1950
    },
    {
      "epoch": 39.2,
      "grad_norm": 0.0045899259857833385,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0007,
      "step": 1960
    },
    {
      "epoch": 39.4,
      "grad_norm": 0.00507607264444232,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 0.0008,
      "step": 1970
    },
    {
      "epoch": 39.6,
      "grad_norm": 0.004864298272877932,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0008,
      "step": 1980
    },
    {
      "epoch": 39.8,
      "grad_norm": 0.004812796134501696,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 0.0007,
      "step": 1990
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.016315262764692307,
      "learning_rate": 1.25e-05,
      "loss": 0.0008,
      "step": 2000
    },
    {
      "epoch": 40.2,
      "grad_norm": 0.0044927773997187614,
      "learning_rate": 1.225e-05,
      "loss": 0.0008,
      "step": 2010
    },
    {
      "epoch": 40.4,
      "grad_norm": 0.014707731083035469,
      "learning_rate": 1.2e-05,
      "loss": 0.0007,
      "step": 2020
    },
    {
      "epoch": 40.6,
      "grad_norm": 0.004281255882233381,
      "learning_rate": 1.175e-05,
      "loss": 0.0007,
      "step": 2030
    },
    {
      "epoch": 40.8,
      "grad_norm": 0.004432922229170799,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 0.0008,
      "step": 2040
    },
    {
      "epoch": 41.0,
      "grad_norm": 0.00611808430403471,
      "learning_rate": 1.125e-05,
      "loss": 0.0007,
      "step": 2050
    },
    {
      "epoch": 41.2,
      "grad_norm": 0.004262969829142094,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0007,
      "step": 2060
    },
    {
      "epoch": 41.4,
      "grad_norm": 0.00783385057002306,
      "learning_rate": 1.075e-05,
      "loss": 0.0118,
      "step": 2070
    },
    {
      "epoch": 41.6,
      "grad_norm": 0.004605040419846773,
      "learning_rate": 1.05e-05,
      "loss": 0.0008,
      "step": 2080
    },
    {
      "epoch": 41.8,
      "grad_norm": 0.004310628864914179,
      "learning_rate": 1.025e-05,
      "loss": 0.0007,
      "step": 2090
    },
    {
      "epoch": 42.0,
      "grad_norm": 0.006728924810886383,
      "learning_rate": 1e-05,
      "loss": 0.0007,
      "step": 2100
    },
    {
      "epoch": 42.2,
      "grad_norm": 0.005516661796718836,
      "learning_rate": 9.750000000000002e-06,
      "loss": 0.0021,
      "step": 2110
    },
    {
      "epoch": 42.4,
      "grad_norm": 0.0070012761279940605,
      "learning_rate": 9.5e-06,
      "loss": 0.0007,
      "step": 2120
    },
    {
      "epoch": 42.6,
      "grad_norm": 0.01355741173028946,
      "learning_rate": 9.25e-06,
      "loss": 0.0007,
      "step": 2130
    },
    {
      "epoch": 42.8,
      "grad_norm": 0.004649050068110228,
      "learning_rate": 9e-06,
      "loss": 0.0007,
      "step": 2140
    },
    {
      "epoch": 43.0,
      "grad_norm": 0.012210714630782604,
      "learning_rate": 8.75e-06,
      "loss": 0.0008,
      "step": 2150
    },
    {
      "epoch": 43.2,
      "grad_norm": 0.005592104513198137,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.0007,
      "step": 2160
    },
    {
      "epoch": 43.4,
      "grad_norm": 0.004979188088327646,
      "learning_rate": 8.25e-06,
      "loss": 0.0007,
      "step": 2170
    },
    {
      "epoch": 43.6,
      "grad_norm": 0.004560175817459822,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0007,
      "step": 2180
    },
    {
      "epoch": 43.8,
      "grad_norm": 0.004229098092764616,
      "learning_rate": 7.75e-06,
      "loss": 0.0007,
      "step": 2190
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.008948041126132011,
      "learning_rate": 7.5e-06,
      "loss": 0.0007,
      "step": 2200
    },
    {
      "epoch": 44.2,
      "grad_norm": 0.004668323788791895,
      "learning_rate": 7.25e-06,
      "loss": 0.0007,
      "step": 2210
    },
    {
      "epoch": 44.4,
      "grad_norm": 0.004522422328591347,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.0007,
      "step": 2220
    },
    {
      "epoch": 44.6,
      "grad_norm": 0.004304354079067707,
      "learning_rate": 6.750000000000001e-06,
      "loss": 0.0007,
      "step": 2230
    },
    {
      "epoch": 44.8,
      "grad_norm": 0.004212933126837015,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0007,
      "step": 2240
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.02318672463297844,
      "learning_rate": 6.25e-06,
      "loss": 0.0008,
      "step": 2250
    },
    {
      "epoch": 45.2,
      "grad_norm": 0.005309929605573416,
      "learning_rate": 6e-06,
      "loss": 0.0007,
      "step": 2260
    },
    {
      "epoch": 45.4,
      "grad_norm": 0.004910569172352552,
      "learning_rate": 5.750000000000001e-06,
      "loss": 0.0007,
      "step": 2270
    },
    {
      "epoch": 45.6,
      "grad_norm": 0.004455214831978083,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.0007,
      "step": 2280
    },
    {
      "epoch": 45.8,
      "grad_norm": 0.0041427165269851685,
      "learning_rate": 5.25e-06,
      "loss": 0.0007,
      "step": 2290
    },
    {
      "epoch": 46.0,
      "grad_norm": 0.6282485723495483,
      "learning_rate": 5e-06,
      "loss": 0.0008,
      "step": 2300
    },
    {
      "epoch": 46.2,
      "grad_norm": 0.003949564881622791,
      "learning_rate": 4.75e-06,
      "loss": 0.0007,
      "step": 2310
    },
    {
      "epoch": 46.4,
      "grad_norm": 0.0046889204531908035,
      "learning_rate": 4.5e-06,
      "loss": 0.0007,
      "step": 2320
    },
    {
      "epoch": 46.6,
      "grad_norm": 0.058954425156116486,
      "learning_rate": 4.250000000000001e-06,
      "loss": 0.0007,
      "step": 2330
    },
    {
      "epoch": 46.8,
      "grad_norm": 0.004228818230330944,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0007,
      "step": 2340
    },
    {
      "epoch": 47.0,
      "grad_norm": 0.004704569466412067,
      "learning_rate": 3.75e-06,
      "loss": 0.0006,
      "step": 2350
    },
    {
      "epoch": 47.2,
      "grad_norm": 0.003991477191448212,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 0.0006,
      "step": 2360
    },
    {
      "epoch": 47.4,
      "grad_norm": 0.005825447849929333,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 0.0007,
      "step": 2370
    },
    {
      "epoch": 47.6,
      "grad_norm": 0.004458033014088869,
      "learning_rate": 3e-06,
      "loss": 0.0007,
      "step": 2380
    },
    {
      "epoch": 47.8,
      "grad_norm": 0.0044707078486680984,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 0.0007,
      "step": 2390
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.008181646466255188,
      "learning_rate": 2.5e-06,
      "loss": 0.0007,
      "step": 2400
    },
    {
      "epoch": 48.2,
      "grad_norm": 0.0044989874586462975,
      "learning_rate": 2.25e-06,
      "loss": 0.0006,
      "step": 2410
    },
    {
      "epoch": 48.4,
      "grad_norm": 0.004253502935171127,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0007,
      "step": 2420
    },
    {
      "epoch": 48.6,
      "grad_norm": 0.004451913293451071,
      "learning_rate": 1.7500000000000002e-06,
      "loss": 0.0007,
      "step": 2430
    },
    {
      "epoch": 48.8,
      "grad_norm": 0.0040169465355575085,
      "learning_rate": 1.5e-06,
      "loss": 0.0007,
      "step": 2440
    },
    {
      "epoch": 49.0,
      "grad_norm": 0.007874628528952599,
      "learning_rate": 1.25e-06,
      "loss": 0.0116,
      "step": 2450
    },
    {
      "epoch": 49.2,
      "grad_norm": 0.004494665190577507,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0007,
      "step": 2460
    },
    {
      "epoch": 49.4,
      "grad_norm": 0.0039282566867768764,
      "learning_rate": 7.5e-07,
      "loss": 0.0007,
      "step": 2470
    },
    {
      "epoch": 49.6,
      "grad_norm": 0.0053410157561302185,
      "learning_rate": 5.000000000000001e-07,
      "loss": 0.0007,
      "step": 2480
    },
    {
      "epoch": 49.8,
      "grad_norm": 0.004253688268363476,
      "learning_rate": 2.5000000000000004e-07,
      "loss": 0.0007,
      "step": 2490
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.005405345931649208,
      "learning_rate": 0.0,
      "loss": 0.0006,
      "step": 2500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2286167298864000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
